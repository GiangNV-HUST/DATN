"""
Stock Analysis Agent - Gemini Version
Agent sá»­ dá»¥ng Google Gemini vá»›i MCP Integration
"""

import asyncio
import aiohttp
import json
import logging
from typing import Dict, Any, List, Optional
import google.generativeai as genai
import sys
import os

sys.path.insert(0, os.path.abspath(os.path.join(os.path.dirname(__file__), "../..")))
from src.config import Config

logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s - %(name)s - %(levelname)s - %(message)s"
)
logger = logging.getLogger(__name__)


class GeminiStockAgent:
    """AI Agent vá»›i Gemini vÃ  MCP Integration"""

    def __init__(
        self,
        gemini_api_key: Optional[str] = None,
        mcp_server_url: str = "http://localhost:5000",
        model_name: str = "gemini-2.5-flash-lite"
    ):
        """
        Khá»Ÿi táº¡o Gemini Agent

        Args:
            gemini_api_key: API key cho Google Gemini (náº¿u None, láº¥y tá»« env)
            mcp_server_url: URL cá»§a MCP server
            model_name: TÃªn model Gemini (gemini-2.5-flash-lite)
        """
        self.gemini_api_key = gemini_api_key or Config.GEMINI_API_KEY
        self.mcp_server_url = mcp_server_url
        self.model_name = model_name

        # Configure Gemini
        genai.configure(api_key=self.gemini_api_key)

        # Initialize model vá»›i function calling
        self.model = genai.GenerativeModel(
            model_name=self.model_name,
            system_instruction=self._get_system_prompt()
        )

        self.mcp_tools = []
        self.gemini_tools = []  # Tools á»Ÿ format Gemini
        self.conversation_history = []

        logger.info("âœ… Gemini Stock Agent initialized")
        logger.info(f"ğŸ¤– Model: {model_name}")
        logger.info(f"ğŸ”— MCP Server: {mcp_server_url}")

    async def discover_tools(self) -> List[Dict[str, Any]]:
        """
        Discover tools tá»« MCP server vÃ  convert sang Gemini format

        Returns:
            List cÃ¡c tool schemas
        """
        try:
            async with aiohttp.ClientSession() as session:
                async with session.get(f"{self.mcp_server_url}/tools/schema") as resp:
                    if resp.status == 200:
                        data = await resp.json()
                        if data.get("success"):
                            self.mcp_tools = data["schemas"]
                            # Convert to Gemini format
                            self.gemini_tools = self._convert_to_gemini_tools(self.mcp_tools)

                            logger.info(f"ğŸ”§ Discovered {len(self.mcp_tools)} tools from MCP server")
                            for tool in self.mcp_tools:
                                logger.info(f"   - {tool['name']}: {tool['description'][:50]}...")
                            return self.mcp_tools
                        else:
                            logger.error(f"Failed to get schemas: {data.get('error')}")
                            return []
                    else:
                        logger.error(f"MCP server returned status {resp.status}")
                        return []
        except Exception as e:
            logger.error(f"âŒ Failed to discover tools: {e}")
            return []

    def _convert_to_gemini_tools(self, mcp_tools: List[Dict]) -> List:
        """
        Convert MCP tool schemas sang Gemini function declarations

        Args:
            mcp_tools: List tool schemas tá»« MCP

        Returns:
            List Gemini function declarations
        """
        gemini_functions = []

        for tool in mcp_tools:
            # Gemini function declaration format
            function_decl = genai.protos.FunctionDeclaration(
                name=tool["name"],
                description=tool["description"],
                parameters=genai.protos.Schema(
                    type=genai.protos.Type.OBJECT,
                    properties={
                        prop_name: genai.protos.Schema(
                            type=self._map_type_to_gemini(prop_schema.get("type", "string")),
                            description=prop_schema.get("description", "")
                        )
                        for prop_name, prop_schema in tool["input_schema"]["properties"].items()
                    },
                    required=tool["input_schema"].get("required", [])
                )
            )
            gemini_functions.append(function_decl)

        return [genai.protos.Tool(function_declarations=gemini_functions)]

    def _map_type_to_gemini(self, json_type: str) -> genai.protos.Type:
        """Map JSON schema type to Gemini type"""
        type_mapping = {
            "string": genai.protos.Type.STRING,
            "number": genai.protos.Type.NUMBER,
            "integer": genai.protos.Type.INTEGER,
            "boolean": genai.protos.Type.BOOLEAN,
            "array": genai.protos.Type.ARRAY,
            "object": genai.protos.Type.OBJECT
        }
        return type_mapping.get(json_type, genai.protos.Type.STRING)

    async def call_mcp_tool(self, tool_name: str, arguments: Dict[str, Any]) -> Dict[str, Any]:
        """
        Gá»i má»™t tool trÃªn MCP server

        Args:
            tool_name: TÃªn tool
            arguments: Arguments cho tool

        Returns:
            Káº¿t quáº£ tá»« tool
        """
        try:
            logger.info(f"ğŸ”§ Calling MCP tool: {tool_name}({arguments})")

            async with aiohttp.ClientSession() as session:
                async with session.post(
                    f"{self.mcp_server_url}/tools/call",
                    json={"tool": tool_name, "arguments": arguments}
                ) as resp:
                    if resp.status == 200:
                        result = await resp.json()
                        logger.info(f"âœ… Tool result: {json.dumps(result, ensure_ascii=False)[:200]}...")
                        return result
                    else:
                        error = await resp.text()
                        logger.error(f"MCP tool call failed: {error}")
                        return {
                            "success": False,
                            "error": f"HTTP {resp.status}: {error}"
                        }
        except Exception as e:
            logger.error(f"âŒ Error calling MCP tool: {e}")
            return {
                "success": False,
                "error": str(e)
            }

    async def chat_with_tools(self, user_message: str, max_iterations: int = 10) -> str:
        """
        Chat vá»›i Gemini agent, tá»± Ä‘á»™ng gá»i MCP tools khi cáº§n

        Args:
            user_message: Tin nháº¯n tá»« user
            max_iterations: Sá»‘ láº§n tá»‘i Ä‘a cho phÃ©p gá»i tools

        Returns:
            CÃ¢u tráº£ lá»i cuá»‘i cÃ¹ng
        """
        # Start chat session vá»›i tools
        chat = self.model.start_chat(
            history=self.conversation_history,
            enable_automatic_function_calling=False  # Manual control
        )

        iteration = 0
        current_message = user_message

        while iteration < max_iterations:
            try:
                # Send message vá»›i tools
                response = chat.send_message(
                    current_message,
                    tools=self.gemini_tools if self.gemini_tools else None
                )

                logger.info(f"ğŸ¤– Gemini response parts: {len(response.parts)}")

                # Check for function calls
                function_calls = []
                text_response = []

                for part in response.parts:
                    if part.function_call:
                        function_calls.append(part.function_call)
                    elif part.text:
                        text_response.append(part.text)

                # Náº¿u khÃ´ng cÃ³ function calls, tráº£ vá» text response
                if not function_calls:
                    final_text = "".join(text_response)

                    # Update history
                    self.conversation_history = chat.history

                    return final_text if final_text else "âŒ KhÃ´ng cÃ³ response"

                # Execute function calls
                logger.info(f"ğŸ”§ Gemini wants to call {len(function_calls)} function(s)")

                function_responses = []
                for fc in function_calls:
                    tool_name = fc.name
                    tool_args = dict(fc.args)

                    logger.info(f"   - {tool_name}({tool_args})")

                    # Call MCP tool
                    result = await self.call_mcp_tool(tool_name, tool_args)

                    # Format response for Gemini
                    function_responses.append(
                        genai.protos.Part(
                            function_response=genai.protos.FunctionResponse(
                                name=tool_name,
                                response={"result": result}
                            )
                        )
                    )

                # Send function results back to Gemini
                current_message = function_responses
                iteration += 1

            except Exception as e:
                logger.error(f"âŒ Error in chat loop: {e}", exc_info=True)
                raise Exception(f"KhÃ´ng thá»ƒ tráº£ lá»i: {str(e)}")

        # Max iterations reached
        return "âŒ ÄÃ£ vÆ°á»£t quÃ¡ sá»‘ láº§n gá»i tools cho phÃ©p. Vui lÃ²ng thá»­ láº¡i vá»›i cÃ¢u há»i Ä‘Æ¡n giáº£n hÆ¡n."

    def _get_system_prompt(self) -> str:
        """System prompt cho agent"""
        return """Báº¡n lÃ  AI Stock Analysis Agent chuyÃªn phÃ¢n tÃ­ch cá»• phiáº¿u Viá»‡t Nam.

Báº¡n cÃ³ quyá»n truy cáº­p cÃ¡c MCP tools Ä‘á»ƒ láº¥y dá»¯ liá»‡u thá»±c:
1. get_latest_price - Láº¥y giÃ¡ vÃ  chá»‰ bÃ¡o ká»¹ thuáº­t má»›i nháº¥t
2. get_price_history - Láº¥y lá»‹ch sá»­ giÃ¡ Ä‘á»ƒ phÃ¢n tÃ­ch xu hÆ°á»›ng
3. get_predictions - Láº¥y dá»± Ä‘oÃ¡n giÃ¡ tá»« mÃ´ hÃ¬nh ML
4. search_stocks - TÃ¬m cá»• phiáº¿u theo tiÃªu chÃ­ ká»¹ thuáº­t

HÆ°á»›ng dáº«n:
- Khi ngÆ°á»i dÃ¹ng há»i vá» cá»• phiáº¿u, hÃ£y Sá»¬ Dá»¤NG TOOLS Ä‘á»ƒ láº¥y dá»¯ liá»‡u thá»±c
- PhÃ¢n tÃ­ch dá»¯ liá»‡u chi tiáº¿t, giáº£i thÃ­ch Ã½ nghÄ©a cÃ¡c chá»‰ bÃ¡o
- ÄÆ°a ra nháº­n xÃ©t vÃ  khuyáº¿n nghá»‹ dá»±a trÃªn dá»¯ liá»‡u
- Format cÃ¢u tráº£ lá»i rÃµ rÃ ng, dá»… hiá»ƒu vá»›i emoji

LÆ°u Ã½: PhÃ¢n tÃ­ch chá»‰ mang tÃ­nh tham kháº£o, khÃ´ng pháº£i lá»i khuyÃªn Ä‘áº§u tÆ°."""

    def clear_history(self):
        """XÃ³a conversation history"""
        self.conversation_history = []
        logger.info("ğŸ§¹ Conversation history cleared")

    def analyze_stock(self, ticker: str) -> str:
        """
        PhÃ¢n tÃ­ch cá»• phiáº¿u (sync wrapper)

        Args:
            ticker: MÃ£ cá»• phiáº¿u

        Returns:
            PhÃ¢n tÃ­ch chi tiáº¿t
        """
        return asyncio.run(self.chat_with_tools(
            f"HÃ£y phÃ¢n tÃ­ch toÃ n diá»‡n cá»• phiáº¿u {ticker}. "
            f"Láº¥y giÃ¡ hiá»‡n táº¡i, lá»‹ch sá»­, vÃ  dá»± Ä‘oÃ¡n Ä‘á»ƒ Ä‘Æ°a ra nháº­n xÃ©t chi tiáº¿t."
        ))

    def answer_question(self, question: str) -> str:
        """
        Tráº£ lá»i cÃ¢u há»i (sync wrapper)

        Args:
            question: CÃ¢u há»i tá»« user

        Returns:
            CÃ¢u tráº£ lá»i
        """
        return asyncio.run(self.chat_with_tools(question))


async def main():
    """Demo Gemini agent"""
    print("\n" + "="*60)
    print("ğŸ§ª TESTING GEMINI STOCK AGENT - MCP Integration")
    print("="*60 + "\n")

    # Khá»Ÿi táº¡o agent
    agent = GeminiStockAgent(
        mcp_server_url="http://localhost:5000",
        model_name="gemini-2.5-flash-lite"  # hoáº·c "gemini-1.5-pro"
    )

    # Discover tools tá»« MCP server
    print("ğŸ“¡ Discovering tools from MCP server...")
    tools = await agent.discover_tools()

    if not tools:
        print("âŒ No tools discovered. Make sure MCP server is running!")
        print("   Run: python src/AI_agent_v3/mcp_server/stock_mcp_server.py")
        return

    print(f"âœ… Discovered {len(tools)} tools\n")

    # Test queries
    test_queries = [
        "VCB giÃ¡ bao nhiÃªu?",
        # "So sÃ¡nh VCB vÃ  TCB vá» RSI",
    ]

    for query in test_queries:
        print(f"\n{'='*60}")
        print(f"â“ User: {query}")
        print(f"{'='*60}\n")

        response = await agent.chat_with_tools(query)
        print(f"ğŸ¤– Gemini: {response}\n")

        # Clear history between queries
        agent.clear_history()


if __name__ == "__main__":
    try:
        asyncio.run(main())
    except KeyboardInterrupt:
        print("\n\nğŸ‘‹ Stopped by user")
    except Exception as e:
        logger.error(f"âŒ Error: {e}", exc_info=True)
