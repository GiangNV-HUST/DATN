"""
Migration Script: Chuy·ªÉn t·ª´ Moving Average sang ARIMA
C·∫≠p nh·∫≠t predictions trong database s·ª≠ d·ª•ng ARIMA thay v√¨ MA
"""

import sys
import os
import pandas as pd
import psycopg2
from datetime import datetime
import logging

# Add parent directories to path
sys.path.insert(0, os.path.abspath(os.path.join(os.path.dirname(__file__), "../..")))

from src.predictions_arima.arima_predict import ARIMAPredictor
from src.config import Config

logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s - %(name)s - %(levelname)s - %(message)s"
)
logger = logging.getLogger(__name__)


class ARIMAPredictionMigrator:
    """Migrate predictions to ARIMA"""

    def __init__(self):
        self.db_config = {
            "host": Config.DB_HOST,
            "port": Config.DB_PORT,
            "database": Config.DB_NAME,
            "user": Config.DB_USER,
            "password": Config.DB_PASSWORD,
        }

    def get_connection(self):
        """T·∫°o database connection"""
        return psycopg2.connect(**self.db_config)

    def get_all_tickers(self):
        """L·∫•y danh s√°ch t·∫•t c·∫£ ticker"""
        try:
            conn = self.get_connection()
            cur = conn.cursor()

            cur.execute("""
                SELECT DISTINCT ticker
                FROM stock.stock_prices_1d
                ORDER BY ticker
            """)

            tickers = [row[0] for row in cur.fetchall()]

            cur.close()
            conn.close()

            return tickers

        except Exception as e:
            logger.error(f"Error getting tickers: {e}")
            return []

    def get_stock_data(self, ticker: str, days: int = 60):
        """L·∫•y d·ªØ li·ªáu c·ªï phi·∫øu"""
        try:
            conn = self.get_connection()
            cur = conn.cursor()

            query = """
                SELECT time, close
                FROM stock.stock_prices_1d
                WHERE ticker = %s
                ORDER BY time DESC
                LIMIT %s
            """

            cur.execute(query, (ticker, days))
            rows = cur.fetchall()

            df = pd.DataFrame(rows, columns=['time', 'close'])
            df = df.sort_values('time')

            cur.close()
            conn.close()

            return df

        except Exception as e:
            logger.error(f"Error getting data for {ticker}: {e}")
            return None

    def update_predictions(self, ticker: str, predictions: list):
        """
        C·∫≠p nh·∫≠t predictions v√†o database

        Args:
            ticker: M√£ c·ªï phi·∫øu
            predictions: [day1, day2, day3]
        """
        try:
            conn = self.get_connection()
            cur = conn.cursor()

            # X√≥a prediction c≈© (n·∫øu c√≥)
            cur.execute("""
                DELETE FROM stock.stock_prices_3d_predict
                WHERE ticker = %s
            """, (ticker,))

            # Insert prediction m·ªõi
            now = datetime.now()
            cur.execute("""
                INSERT INTO stock.stock_prices_3d_predict
                (ticker, time, close_next_1, close_next_2, close_next_3)
                VALUES (%s, %s, %s, %s, %s)
            """, (ticker, now, predictions[0], predictions[1], predictions[2]))

            conn.commit()
            cur.close()
            conn.close()

            logger.info(f"‚úÖ Updated predictions for {ticker}: {predictions}")
            return True

        except Exception as e:
            logger.error(f"Error updating predictions for {ticker}: {e}")
            return False

    def migrate_single_ticker(self, ticker: str):
        """
        Migrate predictions cho 1 ticker

        Args:
            ticker: M√£ c·ªï phi·∫øu

        Returns:
            bool: Success or not
        """
        try:
            logger.info(f"üîÑ Processing {ticker}...")

            # L·∫•y data
            df = self.get_stock_data(ticker)

            if df is None or df.empty:
                logger.warning(f"‚ö†Ô∏è No data for {ticker}")
                return False

            # D·ª± ƒëo√°n b·∫±ng ARIMA
            predictions = ARIMAPredictor.predict_3day_arima(df)

            if predictions is None:
                logger.warning(f"‚ö†Ô∏è Could not predict for {ticker}")
                return False

            # Update database
            success = self.update_predictions(ticker, predictions)

            return success

        except Exception as e:
            logger.error(f"‚ùå Error migrating {ticker}: {e}")
            return False

    def migrate_all(self, limit: int = None):
        """
        Migrate predictions cho t·∫•t c·∫£ tickers

        Args:
            limit: Gi·ªõi h·∫°n s·ªë l∆∞·ª£ng tickers (None = all)
        """
        logger.info(f"\n{'='*60}")
        logger.info(f"üöÄ Starting ARIMA Migration")
        logger.info(f"{'='*60}\n")

        # L·∫•y danh s√°ch tickers
        tickers = self.get_all_tickers()

        if limit:
            tickers = tickers[:limit]

        logger.info(f"üìä Found {len(tickers)} tickers to process\n")

        # Process t·ª´ng ticker
        success_count = 0
        failed_count = 0

        for i, ticker in enumerate(tickers, 1):
            logger.info(f"[{i}/{len(tickers)}] {ticker}")

            success = self.migrate_single_ticker(ticker)

            if success:
                success_count += 1
            else:
                failed_count += 1

            logger.info("")  # Empty line for readability

        # Summary
        logger.info(f"\n{'='*60}")
        logger.info(f"üìä MIGRATION SUMMARY")
        logger.info(f"{'='*60}\n")
        logger.info(f"Total tickers: {len(tickers)}")
        logger.info(f"‚úÖ Success: {success_count}")
        logger.info(f"‚ùå Failed: {failed_count}")
        logger.info(f"Success rate: {success_count/len(tickers)*100:.1f}%")


def main():
    """Main migration function"""
    import argparse

    parser = argparse.ArgumentParser(description="Migrate predictions to ARIMA")
    parser.add_argument("--ticker", type=str, help="Migrate single ticker")
    parser.add_argument("--limit", type=int, help="Limit number of tickers")
    parser.add_argument("--all", action="store_true", help="Migrate all tickers")

    args = parser.parse_args()

    migrator = ARIMAPredictionMigrator()

    if args.ticker:
        # Migrate single ticker
        logger.info(f"üéØ Migrating single ticker: {args.ticker}\n")
        migrator.migrate_single_ticker(args.ticker)

    elif args.all or args.limit:
        # Migrate all or limited
        migrator.migrate_all(limit=args.limit)

    else:
        # Default: migrate 5 tickers for testing
        logger.info("üß™ Test mode: Migrating 5 tickers\n")
        migrator.migrate_all(limit=5)

    logger.info("\n‚úÖ Migration completed!")


if __name__ == "__main__":
    try:
        main()
    except KeyboardInterrupt:
        logger.info("\n\nüëã Migration stopped by user")
    except Exception as e:
        logger.error(f"‚ùå Migration error: {e}", exc_info=True)
