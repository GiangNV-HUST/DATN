version: '3.11'

services: 
  # TimescaleDB - Time-series database cho stock data
  timescaledb:
    image: timescale/timescaledb:latest-pg14
    container_name: stock_timescaledb
    environment:
      POSTGRES_USER: postgres
      POSTGRES_PASSWORD: postgres123
      POSTGRES_DB: stock
    ports:
    - "5434:5432"
    volumes:
      - timescale-data:/var/lib/postgresql/data
      - ./database/init.sql:/docker-entrypoint-initdb.d/01-init.sql
    command: >
      postgres
      -c shared_preload_libraries=timescaledb
      -c timescaledb.telemetry_level=off
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U postgres"]
      interval: 10s
      timeout: 5s
      retries: 5
    restart: always
    networks:
      - stock-network


  # ==========================================================================
  # POSTGRES FOR AIRFLOW METADATA
  # ==========================================================================
  postgres-airflow:
    image: postgres:14
    container_name: stock-postgres-airflow
    environment:
      POSTGRES_USER: airflow
      POSTGRES_PASSWORD: airflow123
      POSTGRES_DB: airflow
    ports:
      - "5433:5432"
    volumes:
      - postgres-airflow-data:/var/lib/postgresql/data
    healthcheck:
      test: ["CMD", "pg_isready","-U","airflow"]
      interval: 10s
      timeout: 5s
      retries: 5
    restart: unless-stopped
    networks:
      - stock-network

  # ==================================================================
  # ZOOKEEPER (kafka cần Zookeeper)
  # ==================================================================
  zookeeper:
    image: confluentinc/cp-zookeeper:7.5.0
    container_name: stock-zookeeper
    environment:
      ZOOKEEPER_CLIENT_PORT: 2181
      ZOOKEEPER_TICK_TIME: 2000
    ports:
      - "2181:2181"
    healthcheck:
      test: ["CMD", "nc", "-z", "localhost", "2181"]
      interval: 10s
      timeout: 5s
      retries: 5
    restart: unless-stopped
    networks:
      - stock-network
  
  # ==========================================================================
  # KAFKA BROKER
  # ==========================================================================
  kafka:
    image: confluentinc/cp-kafka:7.5.0
    container_name: stock-kafka
    depends_on:
      zookeeper:
        condition: service_healthy
    ports:
      - "9092:9092"
      - "9093:9093"
    environment:
      KAFKA_BROKER_ID: 1
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT, PLAINTEXT_HOST:PLAINTEXT
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka:29092,PLAINTEXT_HOST://localhost:9092
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_TRANSACTION_STATE_LOG_MIN_ISR: 1
      KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: 1
      KAFKA_AUTO_CREATE_TOPICS_ENABLE: 'true'
      KAFKA_LOG_RETENTION_HOURS: 168
    
    healthcheck:
      test: ["CMD", "kafka-broker-api-versions", "--bootstrap-server","localhost:9092"]
      interval: 10s
      timeout: 10s
      retries: 5
    restart: unless-stopped
    networks:
      - stock-network

  # ====================================================================================
  # KAFKA UI (Web interface để quản lý kafka)
  # ====================================================================================
  kafka-ui:
    image: provectuslabs/kafka-ui:latest
    container_name: stock-kafka-ui
    depends_on:
      kafka:
        condition: service_healthy
    ports:
      - "8080:8080"
    environment:
      KAFKA_CLUSTERS_0_NAME: stock_cluster
      KAFKA_CLUSTERS_0_BOOTSTRAPSERVERS: kafka:29092
      DYNAMIC_CONFIG_ENABLED: 'true'
    restart: unless-stopped
    networks:
      - stock-network
  
  # ==================================================================================
  # AIRFLOW WEBSERVER
  # ==================================================================================
  airflow-webserver:
    build:
      context: .
      dockerfile: airflow.DockerFile
    container_name: stock-airflow-webserver
    depends_on:
      postgres-airflow:
        condition: service_healthy
      airflow-init:
        condition: service_completed_successfully
    environment:
      AIRFLOW__CORE__EXECUTOR: LocalExecutor
      AIRFLOW__DATABASE__SQL_ALCHEMY_CONN: postgresql+psycopg2://airflow:airflow123@postgres-airflow/airflow
      AIRFLOW__CORE__FERNET_KEY: ''
      AIRFLOW__CORE__DAGS_ARE_PAUSED_AT_CREATION: 'true'
      AIRFLOW__CORE__LOAD_EXAMPLES: 'false'
      AIRFLOW__WEBSERVER__EXPOSE_CONFIG: 'true'
      # Custom env
      DB_HOST: timescaledb
      DB_PORT: 5432
      DB_NAME: stock
      DB_USER: postgres
      DB_PASSWORD: postgres123
      KAFKA_BOOTSTRAP_SERVERS: kafka:29092
      KAFKA_TOPIC_STOCK_PRICES: stock_prices_daily
    volumes:
      - ./dag:/opt/airflow/dags
      - ./logs:/opt/airflow/logs
      - ./plugins:/opt/airflow/plugins
      - ./src:/opt/airflow/src
    ports:
      - "8081:8080"
    command: webserver
    healthcheck:
      test: ["CMD", "crul","--fail","http://localhost:8080/health"]
      interval: 30s
      timeout: 10s
      retries: 5
    restart: unless-stopped
    networks:
      - stock-network

  # =================================================================================
  # AIRFLOW SCHEDULER
  # =================================================================================
  airflow-scheduler:
    build:
      context: .
      dockerfile: airflow.DockerFile
    container_name: stock-airflow-scheduler
    depends_on:
      postgres-airflow:
        condition: service_healthy
      airflow-init:
        condition: service_completed_successfully
    environment:
      AIRFLOW__CORE__EXECUTOR: LocalExecutor
      AIRFLOW__DATABASE__SQL_ALCHEMY_CONN: postgresql+psycopg2://airflow:airflow123@postgres-airflow/airflow
      AIRFLOW__CORE__FERNET_KEY: ''
      AIRFLOW__CORE__DAGS_ARE_PAUSED_AT_CREATION: 'true'
      AIRFLOW__CORE__LOAD_EXAMPLES: 'false'
      # Custom env
      DB_HOST: timescaledb
      DB_PORT: 5432
      DB_NAME: stock
      DB_USER: postgres
      DB_PASSWORD: postgres123
      KAFKA_BOOTSTRAP_SERVERS: kafka:29092
      KAFKA_TOPIC_STOCK_PRICES: stock_prices_daily
    volumes:
      - ./dags:/opt/airflow/dags
      - ./logs:/opt/airflow/logs
      - ./plugins:/opt/airflow/plugins
      - ./src:/opt/airflow/src
    command: scheduler
    healthcheck:
      test: ["CMD", "airflow","jobs","check","--job-type","SchedulerJob"]
      interval: 30s
      timeout: 10s
      retries: 5
    restart: unless-stopped
    networks:
      - stock-network

  # ===========================================================================================
  # AIRFLOW INIT (CHẠY 1 LẦN ĐỂ SETUP DB)
  # ===========================================================================================
  airflow-init:
    build:
      context: .
      dockerfile: airflow.DockerFile
    container_name: stock-airflow-init
    depends_on:
      postgres-airflow:
        condition: service_healthy
    environment:
      AIRFLOW__CORE__EXECUTOR: LocalExecutor
      AIRFLOW__DATABASE__SQL_ALCHEMY_CONN: postgresql+psycopg2://airflow:airflow123@postgres-airflow/airflow
      AIRFLOW__CORE__FERNET_KEY: ''
      AIRFLOW__CORE__LOAD_EXAMPLES: 'false'
    entrypoint: /bin/bash
    command:
      - -c
      - |
        airflow db migrate
        airflow users create --username admin --firstname Admin --lastname User --email admin@example.com --role Admin --password admin
    networks:
      - stock-network

  # ==================================================================================
  # PGADMIN - Web GUI for TimescaleDB
  # ==================================================================================
  pgadmin:
    image: dpage/pgadmin4:latest
    container_name: stock-pgadmin
    environment:
      PGADMIN_DEFAULT_EMAIL: admin@admin.com
      PGADMIN_DEFAULT_PASSWORD: admin
      PGADMIN_CONFIG_SERVER_MODE: 'False'
    ports:
      - "5050:80"
    volumes:
      - pgadmin-data:/var/lib/pgadmin
    depends_on:
      timescaledb:
        condition: service_healthy
    restart: unless-stopped
    networks:
      - stock-network

  # ==================================================================================
  # KAFKA CONSUMER - Process stock data from kafka to TimescaleDB
  # ==================================================================================
  kafka-consumer:
    build:
      context: .
      dockerfile: Dockerfile.consumer
    container_name: stock-kafka-consumer
    depends_on:
      kafka:
        condition: service_healthy
      timescaledb:
        condition: service_healthy
    environment:
      KAFKA_BOOTSTRAP_SERVERS: kafka:29092
      KAFKA_TOPIC_STOCK_PRICES: stock_prices_daily
      DB_HOST: timescaledb
      DB_PORT: 5432
      DB_NAME: stock
      DB_USER: postgres
      DB_PASSWORD: postgres123
      DISCORD_WEBHOOK_URL: https://discord.com/api/webhooks/1441267322164740232/339IMJVP9lf-fqgAPZIBXmsiBAieCIVMEYrE0bXWPaIcvtPnVhORScTw-se3gyetXJ7Q
    volumes:
      - ./src:/app/src
      - ./tests:/app/tests
    restart: unless-stopped
    networks:
      - stock-network

  # ==================================================================================
  # DISCORD BOT - AI-powered stock analysis bot
  # ==================================================================================
  discord-bot:
    build:
      context: .
      dockerfile: Dockerfile.bot
    container_name: stock-discord-bot
    depends_on:
      timescaledb:
        condition: service_healthy
    environment:
      # Database
      DB_HOST: timescaledb
      DB_PORT: 5432
      DB_NAME: stock
      DB_USER: postgres
      DB_PASSWORD: postgres123
      # Discord & AI
      DISCORD_BOT_TOKEN: ${DISCORD_BOT_TOKEN}
      GEMINI_API_KEY: ${GEMINI_API_KEY}
    volumes:
      - ./src:/app/src
      - ./.env:/app/.env
    restart: unless-stopped
    networks:
      - stock-network
    healthcheck:
      test: ["CMD", "python", "-c", "import discord; print('OK')"]
      interval: 30s
      timeout: 10s
      retries: 3


# ====================================================================================
# NETWORKS
# ====================================================================================
networks:
  stock-network:
    driver: bridge


volumes:
  timescale-data:
    driver: local
  postgres-airflow-data:
    driver: local
  pgadmin-data:
    driver: local




      
